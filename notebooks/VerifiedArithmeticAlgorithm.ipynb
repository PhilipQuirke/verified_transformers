{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Verified Arithmetic in Transformers - Describe Model Algorithm\n",
        "\n",
        "This Colab describes the algorithm of Transformer models in terms of model behaviours and algorithmic sub-tasks (analysed in other Colabs and stored in JSON files).\n",
        "\n",
        "The models perform integer addition and/or subtraction e.g. 133357+182243=+0315600 and 123450-345670=-0123230. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens.\n",
        "\n",
        "This Colab follows on from:\n",
        "- https://github.com/PhilipQuirke/verified_transformers/blob/main/notebooks/VerifiedArithmeticTrain.ipynb trained the models. It outputs model_name.pth and model_name_train.json\n",
        "- https://github.com/PhilipQuirke/verified_transformers/blob/main/notebooks/VerifiedArithmeticAnalyse.ipynb analyzes the models. It documents their sub-tasks in model_name_behavior.json model_name_maths.json\n",
        "\n",
        "This Colab loads the above json files from HuggingFace repository https://huggingface.co/PhilipQuirke/VerifiedArithmetic/raw/main\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries.\n",
        "\n",
        "Imports \"verified_transformer\" public library as \"qt\". This library is specific to this CoLab's \"QuantaTool\" approach to transformer analysis. Refer to [README.md](https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md) for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCdmr6-_Jkzi"
      },
      "outputs": [],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    !pip install matplotlib\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "\n",
        "    !pip install numpy\n",
        "    #!pip install scikit-learn\n",
        "    !pip install huggingface_hub\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "    def setup_jupyter(install_libraries=False):\n",
        "        if install_libraries:\n",
        "            !pip install matplotlib==3.8.4\n",
        "            !pip install kaleido==0.2.1\n",
        "            !pip install transformer_lens==1.15.0\n",
        "            !pip install torchtyping==0.1.4\n",
        "            !pip install numpy==1.26.4\n",
        "            !pip install plotly==5.20.0\n",
        "            !pip install pytest==8.1.1\n",
        "            #!pip install scikit-learn==1.4.1.post1\n",
        "\n",
        "        print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "        from IPython import get_ipython\n",
        "\n",
        "        ipython = get_ipython()\n",
        "        # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "        ipython.magic(\"load_ext autoreload\")\n",
        "        ipython.magic(\"autoreload 2\")\n",
        "\n",
        "    # setup_jupyter(install_libraries=True)   # Uncomment if you need to install libraries in notebook.\n",
        "    setup_jupyter(install_libraries=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import textwrap\n",
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "\n",
        "import re\n",
        "import sklearn # Aka scikit.learn\n",
        "import skopt # Aka scikit.optimize"
      ],
      "metadata": {
        "id": "tUI-Jl3B5Ppf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2P3cndolKDM"
      },
      "outputs": [],
      "source": [
        "# Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md\n",
        "!pip install --upgrade git+https://github.com/PhilipQuirke/verified_transformers.git  # Specify @branch if testing a specific branch\n",
        "import QuantaTools as qt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to analyze?\n",
        "\n",
        "The existing model weightings created by the sister Colab [VerifiedArithmeticTrain](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/VerifiedArithmeticTrain.ipynb) are loaded from HuggingFace (in Part 5). Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"main\" configuration class. MathsConfig is derived from the chain AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = qt.MathsConfig()\n",
        "\n",
        "# Which model do we want to analyze? Uncomment one line:\n",
        "\n",
        "# Addition models\n",
        "#cfg.set_model_names( \"add_d5_l1_h3_t15K_s372001\" )  # AddAccuracy=Two9s. Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions.\n",
        "#cfg.set_model_names( \"add_d5_l2_h3_t15K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.6e-08\n",
        "#cfg.set_model_names( \"add_d5_l2_h3_t40K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=2e-09. Fewest nodes\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t15K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.7e-08. MAIN FOCUS\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t20K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.5e-08\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t20K_s572091\" )  # AddAccuracy=Six9s. AvgFinalLoss=7e-09\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t40K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss 2e-09. Fewest nodes\n",
        "#cfg.set_model_names( \"add_d10_l2_h3_t40K_s572091\" ) # AddAccuracy=Six9s. AvgFinalLoss=7e-09. (1/M fail: 0000000555+0000000445=+00000001000 ModelAnswer: +00000000900)\n",
        "#cfg.set_model_names( \"add_d10_l2_h3_t40K_gf_s572091\" ) # AddAccuracy=Six9s. AvgFinalLoss=3.5-09. GrokFast.\n",
        "\n",
        "# Subtraction model\n",
        "#cfg.set_model_names( \"sub_d6_l2_h3_t30K_s372001\" )  # SubAccuracy=Six9s. AvgFinalLoss=5.8e-06\n",
        "#cfg.set_model_names( \"sub_d10_l2_h3_t75K_s173289\" )  # SubAccuracy=Two9s. (6672/M fails) AvgFinalLoss=0.002002022\n",
        "#cfg.set_model_names( \"sub_d10_l2_h3_t75K_gf_s173289\" )  # SubAccuracy=Two9s. GrokFast. (5246/M fails) AvgFinalLoss=0.001197\n",
        "\n",
        "# Mixed (addition and subtraction) model\n",
        "#cfg.set_model_names( \"mix_d6_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=5e-09. (1/M fail: 463687+166096=+0629783 ModelAnswer: +0639783)\n",
        "#cfg.set_model_names( \"mix_d10_l3_h4_t75K_s173289\" )  # Add/SubAccuracy=Five9s/Two9s. AvgFinalLoss=1.125e-06 (2/M fail: 3301956441+6198944455=+09500900896 ModelAnswer: +09500800896) (295/M fail: 8531063649-0531031548=+08000032101 ModelAnswer: +07900032101)\n",
        "\n",
        "# Mixed models initialized with addition model\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l2_h3_t40K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgLoss = 2.4e-08 (5/M fails e.g. 565000-364538=+0200462 ModelAnswer: +0100462)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h3_t40K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=1.8e-08. (3/M fails e.g. 072074-272074=-0200000 ModelAnswer: +0200000)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h3_t80K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s AvgLoss = 1.6e-08 (3/M fails e.g. 229672-229678=-0000006 ModelAnswer: +0000006)\n",
        "cfg.set_model_names( \"ins1_mix_d6_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=8e-09. MAIN FOCUS\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t40K_s173289\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.4e-08. (3/M fails e.g. 850038+159060=+1009098 ModelAnswer: +0009098) (2 fails e.g. 77285-477285=+0100000 Q: ModelAnswer: +0000000).\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t50K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=2.9e-08. (4/M fails e.g. 986887-286887=+0700000 ModelAnswer: +0600000)\n",
        "#cfg.set_model_names( \"ins1_mix_d10_l3_h3_t50K_s572091\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss 6.3e-07  (6/M fails e.g. 5068283822+4931712829=+09999996651 ModelAnswer: +19099996651) (7/M fails e.g. 3761900218-0761808615=+03000091603 ModelAnswer: +02000091603)\n",
        "#cfg.set_model_names( \"ins1_mix_d10_l3_h3_t50K_gf_s572091\" ) # Add/SubAccuracy=???/???. GrokFast. Unenriched data.\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads every 100 epochs.\n",
        "#cfg.set_model_names( \"ins2_mix_d6_l4_h4_t40K_s372001\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.7e-08. (3/M fails e.g. 530757+460849=+0991606 ModelAnswer: +0091606) (8 fails e.g. 261926-161857=+0100069 ModelAnswer: +0000069)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads & MLPs every 100 epochs.\n",
        "#cfg.set_model_names( \"ins3_mix_d6_l4_h3_t40K_s372001\" )  # Add/SubAccuracy=Four9s/Two9s. AvgFinalLoss=3.0e-04. (17/M fails e.g. 273257+056745=+0330002 ModelAnswer: +0320002) (3120 fails e,g. 09075-212133=-0003058 ModelAnswer: +0003058)\n",
        "\n",
        "# Mixed models initialized with addition model.\n",
        "#cfg.set_model_names( \"ins4_mix_d6_l3_h4_t30K_s775824\" )  # Add/SubAccuracy=???/??? TODO\n",
        "#cfg.set_model_names( \"ins4_mix_d6_l2_h4_t30K_s775824\" )  # Add/SubAccuracy=???/??? TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BiELcf53ms"
      },
      "outputs": [],
      "source": [
        "cfg.batch_size = 512 # Default analysis batch size\n",
        "if cfg.n_layers >= 3 and cfg.n_heads >= 4:\n",
        "  cfg.batch_size = 256 # Reduce batch size to avoid memory constraint issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0sjS0RN8Bx2"
      },
      "outputs": [],
      "source": [
        "main_fname_pth = cfg.model_name + '.pth'\n",
        "main_fname_train_json = cfg.model_name + '_train.json'\n",
        "main_fname_behavior_json = cfg.model_name + '_behavior.json'\n",
        "main_fname_maths_json = cfg.model_name + '_maths.json'\n",
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rMMFUlpykN8"
      },
      "outputs": [],
      "source": [
        "# Update \"cfg\" with additional training (including cfg.insert_*) config information from stored file:\n",
        "#      https://huggingface.co/PhilipQuirke/VerifiedArithmetic/raw/main/ins1_mix_d6_l3_h4_t40K_s372001_train.json\"\n",
        "training_data_json = qt.download_huggingface_json(main_repo_name, main_fname_train_json)\n",
        "training_loss_list = qt.load_training_json(cfg, training_data_json)\n",
        "print('Loaded main model training config / loss from', main_repo_name, main_fname_train_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "def print_config():\n",
        "  print(\"%Add=\", cfg.perc_add, \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", cfg.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LL_ns72y7UY"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)\n",
        "print('Main model will be read from HuggingLab file', main_repo_name, main_fname_pth)\n",
        "print('Main model training config / loss will be read from HuggingLab file', main_fname_train_json)\n",
        "print('Main model behavior analysis tags will be read from HuggingLab file', main_fname_behavior_json)\n",
        "print('Main model maths analysis tags will be read from HuggingLab file', main_fname_maths_json)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Singleton QuantaTool \"ablation intervention\" configuration class\n",
        "acfg = qt.acfg"
      ],
      "metadata": {
        "id": "-nGkmoCSfgzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3A: Set Up: Vocabulary / Embedding / Unembedding\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeObQk2kzAv7"
      },
      "outputs": [],
      "source": [
        "qt.set_maths_vocabulary(cfg)\n",
        "qt.set_maths_question_meanings(cfg)\n",
        "print(cfg.token_position_meanings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYXz5Ygz0r62"
      },
      "source": [
        "# Part 4: Results: Model training loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWWJn2g-BkAh"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print( \"Avg loss over last 5 epochs\", cfg.avg_final_loss)\n",
        "print( \"Final epoch loss\", cfg.final_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqxO1rj00vaY"
      },
      "outputs": [],
      "source": [
        "if training_loss_list:\n",
        "    answer_digits = cfg.n_digits + 1\n",
        "    title_font_size=32\n",
        "    tick_font_size=24\n",
        "\n",
        "    qt.plot_loss_lines(cfg, 1500, [training_loss_list[:1500]], labels = ['All'], log_y=False,\n",
        "                       title='Training Loss', title_font_size=title_font_size, tick_font_size=tick_font_size)\n",
        "\n",
        "    full_title, fig = qt.plot_loss_lines(cfg, cfg.n_training_steps, [training_loss_list], labels = ['All'], log_y=True,\n",
        "                                         title='Training Loss', title_font_size=title_font_size, tick_font_size=tick_font_size)\n",
        "    pio.write_image(fig, cfg.model_name + '_LogTrainingLoss.' + cfg.graph_file_suffix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVkOJRmPvPms"
      },
      "source": [
        "# Part 6A: Set Up: Load nodes and behaviour tags\n",
        "Load the useful nodes and associated behaviour tags from a JSON file stored on HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naD2eCZevOsi"
      },
      "outputs": [],
      "source": [
        "print(\"Loading useful node list with behavior tags from HuggingFace\", main_repo_name, main_fname_behavior_json)\n",
        "\n",
        "file_path = hf_hub_download(repo_id=main_repo_name, filename=main_fname_behavior_json, revision=\"main\")\n",
        "\n",
        "cfg.useful_nodes.load_nodes(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcCpfmKwlAH"
      },
      "source": [
        "# Part 6B: Results: Show nodes and behaviour tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbzIaqmtwmkH"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.sort_nodes()\n",
        "cfg.useful_nodes.print_node_tags()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tLgDG72GQDg"
      },
      "outputs": [],
      "source": [
        "def show_quanta_map( title, major_tag : qt.QType, minor_tag : str, get_node_details,  \\\n",
        "        image_width_inches : int = 9, image_height_inches : int = 6,\n",
        "        blue_shades : bool = True, cell_num_shades : int = 6,\n",
        "        filters : qt.FilterNode = None, cell_fontsize : int = 9,\n",
        "        combine_identical_cells : bool = True, show_perc_circles : bool = False ): \\\n",
        "\n",
        "  test_nodes = cfg.useful_nodes\n",
        "  if filters is not None:\n",
        "    test_nodes = qt.filter_nodes(test_nodes, filters)\n",
        "\n",
        "  ax1, quanta_results, num_results = qt.calc_quanta_map(\n",
        "      cfg, blue_shades, cell_num_shades,\n",
        "      test_nodes, major_tag.value, minor_tag, get_node_details,\n",
        "      cell_fontsize, combine_identical_cells, show_perc_circles,\n",
        "      image_width_inches, image_height_inches )\n",
        "\n",
        "  if num_results > 0:\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcxRyJXpCCxc"
      },
      "source": [
        "# Part 16A: Results: Show failure percentage map\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-njDS_PKCDMH"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Failure Frequency Behavior Per Node\",\n",
        "                qt.QType.FAIL, \"\", qt.get_quanta_fail_perc,\n",
        "                image_height_inches = 2 * cfg.n_layers,\n",
        "                cell_num_shades = qt.FAIL_SHADES, combine_identical_cells = False, show_perc_circles = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifmtnLoTCN5"
      },
      "source": [
        "# Part 16B - Show answer impact behavior map\n",
        "\n",
        "Show the purpose of each useful cell by impact on the answer digits A0 to Amax.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K9PyCKYTUzX"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Answer Impact Behavior Per Node\",\n",
        "                qt.QType.IMPACT, \"\", qt.get_quanta_impact,\n",
        "                image_height_inches = 2 * cfg.n_layers,\n",
        "                cell_num_shades = cfg.num_answer_positions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avCfaCT1Puhz"
      },
      "source": [
        "# Part 16C: Result: Show attention map\n",
        "\n",
        "Show attention quanta of useful heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTGoEWHgvFH6"
      },
      "outputs": [],
      "source": [
        "# Only maps attention heads, not MLP layers\n",
        "show_quanta_map( \"Attention Behavior Per Head\",\n",
        "                qt.QType.ATTN, \"\", qt.get_quanta_attention,\n",
        "                image_height_inches = 3 * cfg.n_layers,\n",
        "                cell_num_shades = qt.ATTN_SHADES )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7-99ZxDOrbF"
      },
      "source": [
        "# Part 16C - Show question complexity map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKeybAj3d6QU"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show if addition (S), positive-answer subtraction (M) and negative-answer subtraction (N) questions relies on the node.\n",
        "  show_quanta_map( \"Maths Operation Coverage\",\n",
        "                  qt.QType.MATH, \"\", qt.get_maths_operation_complexity,\n",
        "                  image_height_inches = 1.75 * cfg.n_layers,\n",
        "                  blue_shades = False, cell_num_shades = 4, combine_identical_cells = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyoErRoCA-pz"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add > 0:\n",
        "  # For each useful cell, show the minimum addition question complexity that relies on the node, as measured using quanta S0, S1, S2, ...\n",
        "  show_quanta_map( \"Addition Min-Complexity\",\n",
        "                  qt.QType.MATH_ADD, qt.MathsBehavior.ADD_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  image_height_inches = 1.25 * cfg.n_layers,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_ADD_SHADES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMZzbjxUBQGE"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show the minimum \"positive-answer subtraction\" question complexity that relies on the node, as measured using quanta M0, M1, M2, ...\n",
        "  show_quanta_map( \"Positive-answer Subtraction Min-Complexity\",\n",
        "                  qt.QType.MATH_SUB, qt.MathsBehavior.SUB_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  image_height_inches = 1.5 * cfg.n_layers,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_SUB_SHADES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUaT47ettc0M"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show the minimum \"negative-answer subtraction\" question complexity that relies on the node, as measured using quanta N0, N1, N2, ...\n",
        "  show_quanta_map( \"Negative-answer Subtraction Min-Complexity\",\n",
        "                  qt.QType.MATH_NEG, qt.MathsBehavior.NEG_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  image_height_inches = 1.5 * cfg.n_layers,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_SUB_SHADES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ve91mILCxOI"
      },
      "source": [
        "# Part 17: Set Up: Load maths sub-task tags from json file\n",
        "\n",
        "Load the useful nodes maths sub-task tags from a JSON file stored on HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR4rZdgHGBhN"
      },
      "outputs": [],
      "source": [
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\"\n",
        "print(\"Loading maths sub-tasks from HuggingFace\", main_repo_name, main_fname_maths_json)\n",
        "\n",
        "file_path = hf_hub_download(repo_id=main_repo_name, filename=main_fname_maths_json, revision=\"main\")\n",
        "\n",
        "cfg.useful_nodes.load_nodes(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQLfkdlbVAl_"
      },
      "source": [
        "# Part 23A: Show algorithm quanta map\n",
        "\n",
        "Plot the \"maths\" tags as a quanta map. This is an automatically generated partial explanation of the model algorithm.\n",
        "\n",
        "Nodes with multiple tags perform multiple tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g3_iwEkCpcy"
      },
      "outputs": [],
      "source": [
        "qt.print_algo_purpose_results(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9VDbjTAVGrP"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Maths Purpose Per Node\", qt.QType.ALGO, \"\", qt.get_quanta_binary,\n",
        "                #image_width_inches = 11,\n",
        "                cell_num_shades = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_m3qiWYrjRJ"
      },
      "source": [
        "# Part 23B: Show known quanta per answer digit\n",
        "\n",
        "Each of the late positions are soley focused on calculating one answer digit. Show the data have we collected on late answer digit.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT8zKdHz1-fZ"
      },
      "outputs": [],
      "source": [
        "for position in range(cfg.num_question_positions + 1, cfg.n_ctx - 1):\n",
        "  print(\"Position:\", position)\n",
        "\n",
        "  # Calculate a table of the known quanta for the specified position for each late token position\n",
        "  qt.calc_maths_quanta_for_position_nodes(cfg, position)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhheXmLTUfc"
      },
      "source": [
        "# Part 24: Show maths tags\n",
        "\n",
        "Show a list of the nodes that have proved useful in calculations, together with data on the nodes behavior and algorithmic purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRW6tiM8hDOB"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.print_node_tags(qt.QType.ALGO.value, \"\", False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbvzBDwPvoHw"
      },
      "outputs": [],
      "source": [
        "mixed_model = cfg.model_name.startswith(\"ins1_mix_d6_l3_h4_t40K\") or cfg.model_name.startswith(\"ins2_mix_d6_l4_h4_t40K\") or cfg.model_name.startswith(\"ins3_mix_d6_l4_h3_t40K\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D74GWTY3aKhm"
      },
      "source": [
        "# Part 25 : Results: Test Algorithm - Addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmcJq7CEaUZG"
      },
      "outputs": [],
      "source": [
        "print_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyzDudUtU264"
      },
      "outputs": [],
      "source": [
        "# For answer digits (excluding Amax), a An.SA node is needed before the answer digit is revealed\n",
        "def algo_task_search(algo_nodes, from_digit, to_digit, filter_function, mandatory : bool = True):\n",
        "    impact_digit = from_digit\n",
        "    while impact_digit <= to_digit:\n",
        "        cfg.test_algo_clause(algo_nodes, filter_function(impact_digit), mandatory)\n",
        "        impact_digit += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYHKHxh-pHUd"
      },
      "outputs": [],
      "source": [
        "# Read as: And( HasAlgoTag:A4.SA, Position<=A3 )\n",
        "def algo_sa_filter(impact_digit):\n",
        "    return qt.FilterAnd(qt.FilterAlgo(qt.add_sa_functions.tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "\n",
        "# For each question digit, an An.SA node exists before the answer digit is revealed\n",
        "def algo_sa_search(algo_nodes):\n",
        "    algo_task_search(algo_nodes, 0, cfg.n_digits-1, algo_sa_filter)\n",
        "\n",
        "\n",
        "# Read as: And( HasAlgoTag:A4.SC, Position<=A3 )\n",
        "def algo_sc_filter(impact_digit):\n",
        "    return qt.FilterAnd(qt.FilterAlgo(qt.add_sc_functions.tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "\n",
        "# For each question digit, except A0, an An.SC node exists before the answer digit is revealed\n",
        "def algo_sc_search(algo_nodes, mandatory : bool = True):\n",
        "    algo_task_search(algo_nodes, 1, cfg.n_digits-1, algo_sc_filter, mandatory)\n",
        "\n",
        "\n",
        "# Read as: And( HasAlgoTag:A4.SS, Position<=A3 )\n",
        "def algo_ss_filter(impact_digit):\n",
        "    return qt.FilterAnd(qt.FilterAlgo(qt.add_ss_functions.tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "\n",
        "# For each question digit, except A0 and A1, an An.SS node exists before the answer digit is revealed\n",
        "def algo_ss_search(algo_nodes):\n",
        "    algo_task_search(algo_nodes, 2, cfg.n_digits-1, algo_ss_filter)\n",
        "\n",
        "\n",
        "# Read as: And( HasAlgoTag:A4.ST, Position<=Amax )\n",
        "def algo_st_filter(impact_digit):\n",
        "    return qt.FilterAnd(qt.FilterAlgo(qt.add_st_functions.tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(cfg.n_digits+1), qt.QCondition.MAX))\n",
        "\n",
        "# For each question digit, except A0, an An.ST node exists by Amax\n",
        "def algo_st_search(algo_nodes):\n",
        "    algo_task_search(algo_nodes, 2, cfg.n_digits-1, algo_st_filter)\n",
        "\n",
        "\n",
        "# The nodes that implement the ST sub-task must be sequenced so that the SV values can be calculated.\n",
        "def algo_sv_search(algo_nodes):\n",
        "    # TODO: It is not clear what this \"sequencing\" condition is\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGMji2snxax"
      },
      "source": [
        "## Part25A : 1-layer addition models use sub-tasks An.SA, An.SC, An.SS\n",
        "\n",
        "A 1-layer model can do 99% of addition questions using SA, SC and SS sub-tasks (as per Paper 1).\n",
        "\n",
        "For add_d5_l1_h3_t15K_s372001 below search says: 14/15 heads have purpose assigned. 0/6 neurons have purpose assigned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC4oY_HNn5_L"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add > 0 and cfg.n_layers == 1 :\n",
        "\n",
        "    algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "    algo_sa_search(algo_nodes)\n",
        "    algo_sc_search(algo_nodes, mandatory=True)\n",
        "    algo_ss_search(algo_nodes)\n",
        "    algo_sv_search(algo_nodes)\n",
        "\n",
        "    cfg.print_algo_clause_results()\n",
        "    cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZk-BAE2n5kZ"
      },
      "source": [
        "## Part25B : 2-layer addition models use sub-tasks An.SA, An.ST and maybe An.SC\n",
        "\n",
        "A 2-layer model can do 99.9999% of addition questions using SA and ST sub-tasks (as per Paper 2). It may use (redundant) SC sub-tasks.\n",
        "\n",
        "For add_d6_l2_h3_t15K below search says: 21/31 heads have purpose assigned. 0/17 neurons have purpose assigned.\n",
        "\n",
        "TODO: 4 other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cmjOymxluQe"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add > 0 and cfg.n_layers >= 2 :\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  algo_sa_search(algo_nodes)\n",
        "  algo_st_search(algo_nodes)\n",
        "  # SC does the same job as but is less accurate than ST. So the SC nodes are redundant and may be optimised out.\n",
        "  algo_sc_search(algo_nodes, mandatory=False)\n",
        "\n",
        "  cfg.print_algo_clause_results()\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQxhIPzs5K6u"
      },
      "source": [
        "# Part 26: Results: Test Algorithm - Subtraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig0eUEDN5XmG"
      },
      "source": [
        "## Part 26A : 1-layer subtraction uses sub-tasks MD, MB & MZ\n",
        "\n",
        "A 1-layer model can do 99% of subtraction questions using MD, MB and MZ sub-tasks (as per Paper 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_51OgGF3QURv"
      },
      "outputs": [],
      "source": [
        "# Read as: And( HasAlgoTag:A4.MD, Position<=A3 )\n",
        "def algo_md_filter(impact_digit):\n",
        "    return qt.FilterAnd(qt.FilterAlgo(qt.sub_md_functions.tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "\n",
        "# For each question digit, an An.MD node exists before the answer digit is revealed\n",
        "def algo_md_search(algo_nodes):\n",
        "    algo_task_search(algo_nodes, 0, cfg.n_digits-1, algo_md_filter)\n",
        "\n",
        "\n",
        "# Read as: And( HasAlgoTag:A4.MB, Position<=A3 )\n",
        "def algo_mb_filter(impact_digit):\n",
        "    return qt.FilterAnd(qt.FilterAlgo(qt.sub_mb_functions.tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "\n",
        "# For each question digit, an An.MB node exists before the answer digit is revealed\n",
        "def algo_mb_search(algo_nodes, mandatory : bool = True):\n",
        "    algo_task_search(algo_nodes, 0, cfg.n_digits-1, algo_mb_filter, mandatory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axer3RNi6RSG"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0 and cfg.n_layers == 1 :\n",
        "\n",
        "    algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "    algo_md_search(algo_nodes)\n",
        "    algo_mb_search(algo_nodes, mandatory = True)\n",
        "\n",
        "    cfg.print_algo_clause_results()\n",
        "    cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aero_LUu3RX"
      },
      "source": [
        "## Part 26B: Test Algorithm - Subtraction\n",
        "\n",
        "To accurately predict if the answer sign is + or - the model must calculate if D < D'. To calculate this, the model must calculate Dn < D'n or (Dn = D'n and (Dn-1 < D'n-1 or (Dn-2 = D'n-1 and ( etc. It must predict this before the answer sign is revealed.\n",
        "\n",
        "We expect to see nodes useful in negative answer questions, with PCA bigram (or trigram) outputs, attending to these input pairs, evaluated in this order, before the answer sign is revealed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMth-ecxu6NF"
      },
      "outputs": [],
      "source": [
        "def algo_mt_filter(impact_digit,sign_position):\n",
        "    return qt.FilterAnd(\n",
        "      qt.FilterAlgo(qt.sub_mt_functions.tag(impact_digit)),\n",
        "      qt.FilterPosition(sign_position, qt.QCondition.MAX))\n",
        "\n",
        "\n",
        "# For answer digits (excluding Amax), An.MT is needed before the answer digit is revealed\n",
        "def algo_mt_search(algo_nodes):\n",
        "  mt_locations = {}\n",
        "\n",
        "  sign_position = cfg.an_to_position_name(cfg.n_digits+1)\n",
        "\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    # For answer digits (excluding the +/- answer sign and 0 or 1 first answer digit), An.SC is calculated before the answer sign is revealed\n",
        "    position = cfg.test_algo_clause(algo_nodes, algo_mt_filter(impact_digit, sign_position))\n",
        "    mt_locations[impact_digit] = position\n",
        "\n",
        "  # Check that mt_locations[6] < mt_locations[5] < mt_locations[4] < etc\n",
        "  print(\"MT Locations:\", mt_locations)\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    if impact_digit > 0:\n",
        "      sc1 = mt_locations[impact_digit]\n",
        "      sc2 = mt_locations[impact_digit-1]\n",
        "      description = f\"MT Ordering: A{impact_digit}={sc1}, A{impact_digit-1}={sc2}\"\n",
        "      cfg.test_algo_logic(description, sc1 >= 0 and sc2 >= 0 and sc1 < sc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yrAg4sQu9g4"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0 and cfg.n_layers >= 2 :\n",
        "\n",
        "    algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "    algo_md_search(algo_nodes)\n",
        "    algo_mt_search(algo_nodes)\n",
        "    algo_mb_search(algo_nodes, mandatory = False) # TODO: Is this true?\n",
        "\n",
        "    cfg.print_algo_clause_results()\n",
        "    cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCkA6qYCq4iS"
      },
      "source": [
        "# Part 27: Test Algorithm - Mixed Addition and Subtraction model\n",
        "\n",
        "What algorithm do mixed models use to perform both addition and subtraction? Our working hypothesis is Hypothesis 2 as described in https://github.com/PhilipQuirke/verified_transformers/blob/main/mixed_model.md\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFvLmWLf2JA3"
      },
      "source": [
        "## Part 27A: Calculating answer digit A2 in token position A3\n",
        "\n",
        "The below graph displays the same (behavior and algorithm) data as the quanta maps. Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/mixed_model.md section 27A for more explanation.\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1TQpYbs2JcZ"
      },
      "outputs": [],
      "source": [
        "qt.calc_maths_quanta_for_position_nodes(cfg, 18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgasUyOYMG9E"
      },
      "source": [
        "## Part 27.H3 Calculate whether D > D' (using NG tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClNYGvE6Q5T8"
      },
      "outputs": [],
      "source": [
        "filters = qt.FilterContains(qt.QType.MATH_NEG, \"\")\n",
        "\n",
        "#print(\"NG tagged nodes:\", qt.filter_nodes( cfg.useful_nodes, filters ).get_node_names())\n",
        "\n",
        "show_quanta_map( \"Subtraction Behavior NG Nodes\", qt.QType.MATH_SUB, \"\", qt.get_maths_min_complexity, 9, 6, filters=filters, blue_shades=False, cell_num_shades=2)\n",
        "show_quanta_map( \"Attention Behavior Per NG Head\", qt.QType.ATTN, \"\", qt.get_quanta_attention, 9, 8, filters=filters, cell_num_shades=10)\n",
        "show_quanta_map( \"Maths Purpose Per NG Node\", qt.QType.ALGO, \"\", qt.get_quanta_binary, 9, 6, filters=filters, cell_num_shades=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mC4guryMA2k"
      },
      "outputs": [],
      "source": [
        "if mixed_model:\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  algo_sc_search(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vxyIj1FP2Hq"
      },
      "source": [
        "# Part 30: Unit Test automated searches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6g2-mZ5UeJZ"
      },
      "outputs": [],
      "source": [
        "def check_algo_tag_exists(node_location_as_str, the_tags ):\n",
        "  node_location = qt.str_to_node_location(node_location_as_str)\n",
        "  node = cfg.useful_nodes.get_node(node_location)\n",
        "  if node is None:\n",
        "      print( \"Node\", node_location_as_str, \"is missing\")\n",
        "  else:\n",
        "      for the_tag in the_tags:\n",
        "          if not node.contains_tag(qt.QType.ALGO.value, the_tag):\n",
        "              print( \"Node\", node.name(), \"is missing tag\", the_tag, \"It has tags:\", node.tags )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr5SN-tuP1yO"
      },
      "outputs": [],
      "source": [
        "print(cfg.model_name)\n",
        "\n",
        "if cfg.model_name.startswith('add_d6_l2_h3_t15K'):\n",
        "  check_algo_tag_exists('P11L0H0', ['A2.ST'] )\n",
        "  check_algo_tag_exists('P12L0H0', ['A3.ST'] )\n",
        "  check_algo_tag_exists('P14L0H0', ['A5.SS', 'A4.ST'] )\n",
        "  check_algo_tag_exists('P14L0H2', ['A5.SC', 'A5.ST'] )\n",
        "  check_algo_tag_exists('P14L1H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A4.SC'] )\n",
        "  check_algo_tag_exists('P15L0H1', ['A5.SA'] )\n",
        "  check_algo_tag_exists('P15L0H2', ['A5.SA'] )\n",
        "  check_algo_tag_exists('P16L0H0', ['A3.SC'] )\n",
        "  check_algo_tag_exists('P16L0H1', ['A4.SA'] )\n",
        "  check_algo_tag_exists('P16L0H2', ['A4.SA'] )\n",
        "  check_algo_tag_exists('P17L0H0', ['A2.SC'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.SA'] )\n",
        "  check_algo_tag_exists('P17L0H2', ['A3.SA'] )\n",
        "  check_algo_tag_exists('P18L0H0', ['A1.SC'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.SA'] )\n",
        "  check_algo_tag_exists('P18L0H2', ['A2.SA'] )\n",
        "  check_algo_tag_exists('P19L0H0', ['A0.SC'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.SA'] )\n",
        "  check_algo_tag_exists('P19L0H2', ['A1.SA'] )\n",
        "  check_algo_tag_exists('P20L0H1', ['A0.SA'] )\n",
        "  check_algo_tag_exists('P20L0H2', ['A0.SA'] )\n",
        "\n",
        "if cfg.model_name.startswith('mix_d6_l3_h4_t40K'):\n",
        "  check_algo_tag_exists('P8L0H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L2H0', ['A7.NG'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H3', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P16L0H3', ['A4.SA.A4', 'A4.MD.A4'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.NG'] )\n",
        "  check_algo_tag_exists('P17L0H3', ['A3.SA.A3', 'A3.MD.A3'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.NG'] )\n",
        "  check_algo_tag_exists('P18L0H3', ['A2.SA.A2', 'A2.MD.A2'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.NG'] )\n",
        "  check_algo_tag_exists('P19L0H3', ['A1.SA.A1', 'A1.MD.A1'] )\n",
        "  check_algo_tag_exists('P20L0H0', ['A0.SA', 'A0.MD'] )\n",
        "  check_algo_tag_exists('P20L0H3', ['A0.SA', 'A0.MD'] )\n",
        "  check_algo_tag_exists('P20L2H1', ['A0.NG'] )\n",
        "\n",
        "if cfg.model_name.startswith('ins1_mix_d6_l3_h4_t40K'):\n",
        "  check_algo_tag_exists('P6L0H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P9L0H0', ['A4.MT'] )\n",
        "  check_algo_tag_exists('P9L0H1', ['A4.ST'] )\n",
        "  check_algo_tag_exists('P10L0H1', ['A2.MT'] )\n",
        "  check_algo_tag_exists('P10L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P12L0H0', ['A3.MT'] )\n",
        "  check_algo_tag_exists('P12L0H1', ['A3.ST'] )\n",
        "  check_algo_tag_exists('P12L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P12L1H2', ['A1.MT'] )\n",
        "  check_algo_tag_exists('P13L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L1H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L2H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P14L0H0', ['A5.SS', 'OPR'] )\n",
        "  check_algo_tag_exists('P14L0H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P14L0H2', ['A5.SC', 'A5.ST', 'SGN'] )\n",
        "  check_algo_tag_exists('P14L1H2', ['SGN'] )\n",
        "  check_algo_tag_exists('P14L1H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A4.SC'] )\n",
        "  check_algo_tag_exists('P15L0H1', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H2', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L0H0', ['A3.SC'] )\n",
        "  check_algo_tag_exists('P16L0H1', ['A4.SA', 'A4.MD', 'A4.ND'] )\n",
        "  check_algo_tag_exists('P16L0H2', ['A4.SA', 'A4.MD', 'A4.ND'] )\n",
        "  check_algo_tag_exists('P16L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L1H0', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L2H0', ['SGN'] )\n",
        "  check_algo_tag_exists('P17L0H0', ['A2.SC'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.SA', 'A3.MD', 'A3.ND'] )\n",
        "  check_algo_tag_exists('P17L0H2', ['A3.SA', 'A3.MD', 'A3.ND'] )\n",
        "  check_algo_tag_exists('P17L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P18L0H0', ['A1.SC'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.SA', 'A2.MD', 'A2.ND'] )\n",
        "  check_algo_tag_exists('P18L0H2', ['A2.SA', 'A2.MD', 'A2.ND'] )\n",
        "  check_algo_tag_exists('P19L0H0', ['A0.MB.A1'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.SA', 'A1.MD', 'A1.ND'] )\n",
        "  check_algo_tag_exists('P19L0H2', ['A1.SA', 'A1.MD', 'A1.ND'] )\n",
        "  check_algo_tag_exists('P20L0H1', ['A0.SA', 'A0.MD', 'A0.ND'] )\n",
        "  check_algo_tag_exists('P20L0H2', ['A0.SA', 'A0.MD', 'A0.ND'] )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "IVkOJRmPvPms",
        "jFcCpfmKwlAH",
        "bcxRyJXpCCxc",
        "IifmtnLoTCN5",
        "avCfaCT1Puhz",
        "v7-99ZxDOrbF",
        "_ve91mILCxOI",
        "5_m3qiWYrjRJ",
        "LQhheXmLTUfc",
        "D74GWTY3aKhm",
        "PQxhIPzs5K6u",
        "bFvLmWLf2JA3",
        "kgasUyOYMG9E"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}