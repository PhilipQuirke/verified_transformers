{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Accurate Integer Mathematics in Transformers - Analyse the Model\n",
        "\n",
        "This CoLab analyses a Transformer model that performs integer addition, subtraction and multiplication e.g. 133357+182243=+0315600, 123450-345670=-0123230 and 000345*000823=+283935. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries. Don't bother reading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCdmr6-_Jkzi",
        "outputId": "59a5cb02-586c-46b1-a674-45701b8587a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    !pip install matplotlib\n",
        "    !pip install prettytable\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "    !pip install numpy --upgrade\n",
        "    !pip install scikit-learn --upgrade\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from prettytable import PrettyTable\n",
        "import itertools\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqlJ9NjfHeU2"
      },
      "outputs": [],
      "source": [
        "# Import Principal Component Analysis (PCA) library\n",
        "use_pca = True\n",
        "try:\n",
        "  from sklearn.decomposition import PCA\n",
        "except Exception as e:\n",
        "  print(\"pca import failed with exception:\", e)\n",
        "  use_pca = False\n",
        "\n",
        "  # Sometimes version conflicts means the PCA library does not import. This workaround partially fixes the issue\n",
        "  !pip install --upgrade numpy\n",
        "  !pip install --upgrade scikit-learn\n",
        "\n",
        "  # To complete workaround, now select menu option \"Runtime > Restart session and Run all\".\n",
        "  stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyTkeJJ18AAk"
      },
      "outputs": [],
      "source": [
        "# Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md\n",
        "!pip install --upgrade git+https://github.com/PhilipQuirke/verified_transformers.git\n",
        "import QuantaTools as qt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to analyse?\n",
        "\n",
        "The existing model weightings created by the sister Colab [VerifiedArithmeticTrain](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/VerifiedArithmeticTrain.ipynb) are loaded from HuggingFace. Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmjGdFcdJat3"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool configuration class. MathsConfig is derived from AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = qt.MathsConfig()\n",
        "\n",
        "# Singleton QuantaTool ablation intervention configuration class\n",
        "acfg = qt.acfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Which model do we want to analyse? Uncomment one line:\n",
        "\n",
        "#cfg.model_name = \"\" # Use configuration specified in cfg defaults\n",
        "\n",
        "#cfg.model_name = 5-digit and 6-digit digit Addition models\n",
        "#cfg.model_name = \"add_d5_l1_h3_t15K_s372001\"  # Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions.\n",
        "#cfg.model_name = \"add_d5_l2_h3_t15K_s372001\"  # AvgFinalLoss=1.6e-08. Accurate on 1M Qs\n",
        "#cfg.model_name = \"add_d6_l2_h3_t15K_s372001\"  # AvgFinalLoss=1.7e-08. Accurate on 1M Qs\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s173289\"  # AvgFinalLoss=1.5e-08. Accurate on 1M Qs\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s572091\"  # AvgFinalLoss=7e-09. Accurate on 1M Qs\n",
        "\n",
        "# 6-digit Subtraction model\n",
        "#cfg.model_name = \"sub_d6_l2_h3_t30K_s372001\"  # AvgFinalLoss=5.8e-06. Fails 1M Qs\n",
        "\n",
        "# 6-digit Mixed (addition and subtraction) models\n",
        "#cfg.model_name = \"mix_d6_l3_h4_t40K_s372001\"  # AvgFinalLoss=5e-09. Fails 1M Qs\n",
        "\n",
        "#  \"ins1\" 6-digit Mixed models initialised with 6-digit addition model\n",
        "cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s372001\"  # AvgFinalLoss=8e-09. Accurate on 1M Qs for Add and Sub\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s173289\"  # AvgFinalLoss=1.6e-08. 936K for Add, 1M Qs for Sub\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t50K_s572091\"  # AvgFinalLoss=2.9e-08. 1M for Add. 300K for Sub. For 000041-000047=-0000006 gives +0000006. Improve training data.\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h3_t40K_s572091\"  #  AvgFinalLoss=1.8e-08. Fails on 1M Qs. For 099111-099111=+0000000 gives -0000000. Improve training data.\n",
        "\n",
        "# \"ins2\" 6-digit Mixed model initialised with 6-digit addition model. Reset useful heads every 100 epochs.\n",
        "#cfg.model_name = \"ins2_mix_d6_l4_h4_t40K_s372001\"  # AvgFinalLoss=7e-09. Fails 1M Qs\n",
        "\n",
        "# \"ins3\" 6-digit Mixed model initialised with 6-digit addition model. Reset useful heads & MLPs every 100 epochs.\n",
        "#cfg.model_name = \"ins3_mix_d6_l4_h3_t40K_s372001\"  # AvgFinalLoss=2.6e-06. Fails 1M Qs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xozmbk84Hl9v"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BiELcf53ms"
      },
      "outputs": [],
      "source": [
        "# Needed when user changes model_name and reruns this Colab a second time\n",
        "cfg.reset_useful()\n",
        "cfg.reset_algo()\n",
        "cfg.initialize_maths_token_positions()\n",
        "acfg.reset_ablate()\n",
        "\n",
        "if cfg.model_name != \"\":\n",
        "  # Update cfg member data n_digits, n_layers, n_heads, n_training_steps from model_name\n",
        "  cfg.parse_model_name()\n",
        "\n",
        "  # Addition model\n",
        "  cfg.perc_sub = 0\n",
        "  if cfg.model_name.startswith(\"sub_\") :\n",
        "    # Subtraction model\n",
        "    cfg.perc_sub = 100\n",
        "  elif cfg.model_name.startswith(\"mix\") :\n",
        "    # Mixed (addition and subtraction) model\n",
        "    cfg.perc_sub = 66 # Train on 66% subtraction and 33% addition question batches\n",
        "  elif cfg.model_name.startswith(\"ins\") :\n",
        "    # Mixed model initialised with an addition model (using insert mode 1, 2 or 3)\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "\n",
        "  # We train multiple versions of some models, inserting different addition models.\n",
        "  cfg.insert_training_seed = cfg.training_seed\n",
        "\n",
        "  if cfg.model_name.startswith(\"ins1_mix_d6_l3\") :\n",
        "    if cfg.training_seed == 372001:\n",
        "      # Mixed model initialised with add_d6_l2_h3_t15K.pth.\n",
        "      cfg.insert_n_training_steps = 15000\n",
        "    else:\n",
        "      # Mixed model initialised with add_d6_l2_h3_t20K.pth.\n",
        "      cfg.insert_n_training_steps = 20000\n",
        "\n",
        "  cfg.batch_size = 512 # Default analysis batch size\n",
        "  if cfg.n_layers >= 3 and cfg.n_heads >= 4:\n",
        "    cfg.batch_size = 256 # Reduce batch size to avoid memory constraint issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "main_fname = cfg.file_config_prefix()\n",
        "main_fname_pth = main_fname + '.pth'\n",
        "main_fname_behavior_json = main_fname + '_behavior.json'\n",
        "main_fname_algorithm_json = main_fname + '_algorithm.json'\n",
        "\n",
        "def print_config():\n",
        "  print(\"%Add=\", cfg.perc_add(), \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", main_fname)\n",
        "\n",
        "print_config()\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)\n",
        "print('Main model will be read from HuggingLab file', main_fname_pth)\n",
        "print('Main model behavior analysis tags will save to Colab temporary file', main_fname_behavior_json)\n",
        "print('Main model algorithm analysis tags will save to Colab temporary file', main_fname_algorithm_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3A: Set Up: Vocabulary / Embedding / Unembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9NqtFCe18PI"
      },
      "outputs": [],
      "source": [
        "qt.set_maths_vocabulary(cfg)\n",
        "qt.set_maths_question_meanings(cfg)\n",
        "print(cfg.token_position_meanings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6rUaYvjOcE"
      },
      "source": [
        "# Part 3B: Set Up: Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Transformer creation\n",
        "\n",
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = HookedTransformerConfig(\n",
        "    n_layers = cfg.n_layers,\n",
        "    n_heads = cfg.n_heads,\n",
        "    d_model = cfg.d_model,\n",
        "    d_head = cfg.d_head,\n",
        "    d_mlp = cfg.d_mlp(),\n",
        "    act_fn = cfg.act_fn,\n",
        "    normalization_type = 'LN',\n",
        "    d_vocab = cfg.d_vocab,\n",
        "    d_vocab_out = cfg.d_vocab,\n",
        "    n_ctx = cfg.n_ctx(),\n",
        "    init_weights = True,\n",
        "    device = \"cuda\",\n",
        "    seed = cfg.training_seed,\n",
        ")\n",
        "\n",
        "cfg.main_model = HookedTransformer(ht_cfg)\n",
        "\n",
        "optimizer = torch.optim.AdamW(cfg.main_model.parameters(),\n",
        "                        lr = cfg.lr,\n",
        "                        weight_decay = cfg.weight_decay,\n",
        "                        betas = (0.9, 0.98))\n",
        "\n",
        "max_iter = cfg.n_training_steps\n",
        "warmup_iter = max_iter // 5\n",
        "scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=int(warmup_iter))\n",
        "scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(np.ceil((max_iter-warmup_iter))))\n",
        "scheduler  = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2], milestones=[int(warmup_iter)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiJhch4KCej"
      },
      "source": [
        "# Part 4: Set Up: Loss Function & Data Generator\n",
        "This maths loss function and data generator are imported from QuantaTools as logits_to_tokens_loss, loss_fn, maths_data_generator_core and maths_data_generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSkrOJ4S9iA8"
      },
      "outputs": [],
      "source": [
        "# Define \"iterator\" maths \"questions\" data generator function. Invoked using next().\n",
        "ds = qt.maths_data_generator( cfg )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtmioT1THbJA"
      },
      "outputs": [],
      "source": [
        "# Test data generator\n",
        "tokens = next(ds)\n",
        "print(tokens[:3,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5: Set Up: Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0"
      },
      "outputs": [],
      "source": [
        "main_repo_name=\"PhilipQuirke/Accurate6DigitSubtraction\"\n",
        "print(\"Loading model from HuggingFace\", main_repo_name, main_fname_pth)\n",
        "\n",
        "cfg.main_model.load_state_dict(utils.download_file_from_hf(repo_name=main_repo_name, file_name=main_fname_pth, force_is_torch=True))\n",
        "cfg.main_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-yFKiDllqEf"
      },
      "source": [
        "# Part 7A: Set Up: Create sample maths questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMBrZuy7-ivX"
      },
      "outputs": [],
      "source": [
        "varied_questions = qt.make_maths_test_questions_and_answers(cfg)\n",
        "num_varied_questions = varied_questions.shape[0]\n",
        "\n",
        "qt.a_set_ablate_hooks(cfg)\n",
        "qt.a_calc_mean_values(cfg, varied_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-x2-8-q-sb2"
      },
      "outputs": [],
      "source": [
        "print(\"Num questions:\", num_varied_questions, \"Question length:\", len(varied_questions[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6FwJW0tv4Nf"
      },
      "source": [
        "# Part 7B: Results: Can the model correctly predict sample questions?\n",
        "\n",
        "Ask the model to predict the varied_questions (without intervention) to see if the model gets them all right. Categorise answers by complexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z6RdolRKnnR"
      },
      "outputs": [],
      "source": [
        "# Test maths question prediction accuracy on the sample questions provided.\n",
        "# Does NOT use acfg.* or UsefulInfo.* information\n",
        "# Used to estimate the accuracy of the model's predictions.\n",
        "# Returns a reduced set of questions - removing questions that the model failed to answer.\n",
        "print_config()\n",
        "\n",
        "acfg.show_test_failures = True\n",
        "varied_questions = qt.test_maths_questions_by_complexity(cfg, acfg, varied_questions)\n",
        "acfg.show_test_failures = False\n",
        "\n",
        "num_varied_questions = varied_questions.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U7dq4AtDYt3"
      },
      "source": [
        "# Part 10: Set Up: Which token positions are used by the model?\n",
        "\n",
        "Here we ablate all heads in each (question and answer) token position (overriding the model memory aka residual stream) and see if the model's prediction loss increases. If loss increases the token position is used by the algorithm. Unused token positions can be excluded from further analysis.\n",
        "\n",
        "Used to calculate the UsefulInfo.useful_positions. This is (question and answer) **token-position level** information.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpRp5YMmLe1y"
      },
      "outputs": [],
      "source": [
        "num_failures_list = []\n",
        "\n",
        "for position in range(cfg.n_ctx()):\n",
        "  # Test accuracy of model in predicting question answers. Ablates all nodes at acfg.ablate_position\n",
        "  # Does NOT use UsefulInfo.* information. Used to populate UsefulInfo.useful_positions\n",
        "  num_fails = qt.test_maths_questions_by_impact(cfg, acfg, varied_questions, position, True)\n",
        "\n",
        "  num_failures_list += [num_fails] if num_fails > 0 else \".\"\n",
        "\n",
        "  if num_fails > 0:\n",
        "    cfg.add_useful_position(position)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmsGWUbILYin"
      },
      "source": [
        "# Part 11: Results: Which token positions are used by the model?\n",
        "\n",
        "Which token positions are is used in the model's predictions? Unused token positions can be excluded from further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFwcIzTFDgRk"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print(\"num_questions=\", num_varied_questions)\n",
        "print(\"useful_positions=\", cfg.useful_positions )\n",
        "print()\n",
        "\n",
        "cfg.calc_position_failures_map(num_failures_list, 16)\n",
        "qt.save_plt_to_file(cfg=cfg, full_title=\"Failures When Position Ablated\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904WBkTOLg_5"
      },
      "source": [
        "# Part 12A: Set Up: Which nodes are used by the model?\n",
        "\n",
        "Here we ablate each (attention head and MLP neuron) node in each (question and answer) token position see if the model's prediction loss increases. If loss increases then the \"node + token position\" is used by the algorithm. Unused node+positions can be excluded from further analysis.\n",
        "\n",
        "Used to calculate the UsefulInfo.useful_node_location. This is (question and answer) **node+position level** information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as9ot9RMMTAi"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes = qt.UsefulNodeList()\n",
        "\n",
        "acfg.verbose = False\n",
        "qt.ablate_mlp_and_add_useful_node_tags(cfg, varied_questions, qt.test_maths_questions_and_add_useful_node_tags)\n",
        "qt.ablate_head_and_add_useful_node_tags(cfg, varied_questions, qt.test_maths_questions_and_add_useful_node_tags)\n",
        "qt.add_node_attention_tags(cfg, varied_questions)\n",
        "\n",
        "cfg.useful_nodes.sort_nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0pyEjrqEU27"
      },
      "source": [
        "# Part 12B: Results: Which nodes are used by the model?\n",
        "\n",
        "Here are the (attention head and MLP neuron) node in each (question and answer) token position used by the model during predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qWfdiw5EVwA"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.print_node_tags()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmb7c29EEh67"
      },
      "source": [
        " # Part 13: Set up: Show and save Quanta map\n",
        "\n",
        " Using the UsefulNodes and filtering their tags, show a 2D map of the nodes and the tag minor versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3c3i6MEEiag"
      },
      "outputs": [],
      "source": [
        "def show_quanta_map( title, major_tag : qt.QType, minor_tag : str, get_node_details,\n",
        "        image_width_inches : int = 9, image_height_inches : int = 6,\n",
        "        blue_shades : bool = True, cell_num_shades : int = 6,\n",
        "        filters : qt.FilterNode = None, cell_fontsize : int = 9,\n",
        "        combine_identical_cells : bool = True, show_perc_circles : bool = False ):\n",
        "\n",
        "  test_nodes = cfg.useful_nodes\n",
        "  if filters is not None:\n",
        "    test_nodes = qt.filter_nodes(test_nodes, filters)\n",
        "\n",
        "  ax1, quanta_results, num_results = qt.calc_quanta_map(\n",
        "      cfg, blue_shades, cell_num_shades,\n",
        "      test_nodes, major_tag.value, minor_tag, get_node_details,\n",
        "      cell_fontsize, combine_identical_cells, show_perc_circles,\n",
        "      image_width_inches, image_height_inches )\n",
        "\n",
        "  if num_results > 0:\n",
        "    if cfg.graph_file_suffix > \"\":\n",
        "      print(\"Saving quanta map:\", title)\n",
        "      qt.save_plt_to_file(cfg=cfg, full_title=title)\n",
        "    else:\n",
        "      ax1.set_title(cfg.file_config_prefix() + ' ' + title + ' ({} nodes)'.format(len(quanta_results)))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkyhHRoMOSw"
      },
      "source": [
        "# Part 16A: Results: Show failure percentage map\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated.\n",
        "\n",
        "A cell containing \"< 1\" may add some risk to the accuracy of the overall analysis process. Check to see if this represents a new use case. Improve the test data set to contain more instances of this (new or existing) use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ28dx5YLs0P"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Failure Frequency Behavior Per Node\",\n",
        "                qt.QType.FAIL, \"\", qt.get_quanta_fail_perc,\n",
        "                image_height_inches = 2 * cfg.n_layers,\n",
        "                cell_num_shades = qt.FAIL_SHADES, combine_identical_cells = False, show_perc_circles = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avCfaCT1Puhz"
      },
      "source": [
        "# Part 16B - Show answer impact behavior map\n",
        "\n",
        "Show the purpose of each useful cell by impact on the answer digits A0 to Amax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTGoEWHgvFH6"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Answer Impact Behavior Per Node\",\n",
        "                qt.QType.IMPACT, \"\", qt.get_quanta_impact,\n",
        "                image_height_inches = 2 * cfg.n_layers,\n",
        "                cell_num_shades = cfg.num_answer_positions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7-99ZxDOrbF"
      },
      "source": [
        "# Part 16C: Result: Show attention map\n",
        "\n",
        "Show attention quanta of useful heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tAJl0eYO96W"
      },
      "outputs": [],
      "source": [
        "# Only maps attention heads, not MLP layers\n",
        "show_quanta_map( \"Attention Behavior Per Head\",\n",
        "                qt.QType.ATTN, \"\", qt.get_quanta_attention,\n",
        "                image_height_inches = 3 * cfg.n_layers,\n",
        "                cell_num_shades = qt.ATTN_SHADES )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifmtnLoTCN5"
      },
      "source": [
        "# Part 16C - Show question complexity map\n",
        "\n",
        "Show the \"minimum\" addition purpose of each useful cell by S0 to S5 quanta.\n",
        "Show the \"minimum\" subtraction purpose of each useful cell by M0 to M5 quanta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show if addition (S), positive-answer subtraction (M) and negative-answer subtraction (N) questions relies on the node.\n",
        "  show_quanta_map( \"Maths Operation Coverage\",\n",
        "                  qt.QType.MATH, \"\", qt.get_maths_operation_complexity,\n",
        "                  image_height_inches = 1.75 * cfg.n_layers,\n",
        "                  blue_shades = False, cell_num_shades = 4, combine_identical_cells = False)"
      ],
      "metadata": {
        "id": "wzQG6kbDQjBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K9PyCKYTUzX"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  # For each useful cell, show the minimum addition question complexity that relies on the node, as measured using quanta S0, S1, S2, ...\n",
        "  show_quanta_map( \"Addition Min-Complexity\",\n",
        "                  qt.QType.MATH_ADD, qt.MathsBehavior.ADD_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  image_height_inches = 1.25 * cfg.n_layers,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_ADD_SHADES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDNsmgSrFVSO"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show the minimum \"positive-answer subtraction\" question complexity that relies on the node, as measured using quanta M0, M1, M2, ...\n",
        "  show_quanta_map( \"Positive-answer Subtraction Min-Complexity\",\n",
        "                  qt.QType.MATH_SUB, qt.MathsBehavior.SUB_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  image_height_inches = 1.5 * cfg.n_layers,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_SUB_SHADES)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show the minimum \"negative-answer subtraction\" question complexity that relies on the node, as measured using quanta N0, N1, N2, ...\n",
        "  show_quanta_map( \"Negative-answer Subtraction Min-Complexity\",\n",
        "                  qt.QType.MATH_NEG, qt.MathsBehavior.NEG_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  image_height_inches = 1.5 * cfg.n_layers,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_SUB_SHADES)"
      ],
      "metadata": {
        "id": "NsDEJRepWhy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHSY3blNMe7I"
      },
      "source": [
        "#Part 18: Set Up: Calc and graph PCA decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCiBsiQAMhS_"
      },
      "outputs": [],
      "source": [
        "# Create a cache of sample maths questions based on the T8, T9, T10 categorisation in cfg.tricase_questions_dict\n",
        "qt.make_maths_tricase_questions(cfg)\n",
        "\n",
        "def pca_evr_0_percent(pca):\n",
        "  return int(round(pca.explained_variance_ratio_[0]*100,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWCPgoQZMjgc"
      },
      "outputs": [],
      "source": [
        "# Calculate one Principal Component Analysis\n",
        "def calc_pca_for_an(node_location, operation, answer_digit):\n",
        "  assert node_location.is_head == True\n",
        "\n",
        "  try:\n",
        "    t_questions = cfg.tricase_questions_dict[(answer_digit, operation)]\n",
        "\n",
        "    _, the_cache = cfg.main_model.run_with_cache(t_questions)\n",
        "\n",
        "    # Gather attention patterns for all the (randomly chosen) questions\n",
        "    attention_outputs = []\n",
        "    for i in range(len(t_questions)):\n",
        "\n",
        "      # Output of individual heads, without final bias\n",
        "      attention_cache=the_cache[\"result\", node_location.layer, \"attn\"] # Output of individual heads, without final bias\n",
        "      attention_output=attention_cache[i]  # Shape [n_ctx, n_head, d_model]\n",
        "      attention_outputs.append(attention_output[node_location.position, node_location.num, :])\n",
        "\n",
        "    attn_outputs = torch.stack(attention_outputs, dim=0).cpu()\n",
        "\n",
        "    pca = PCA(n_components=6)\n",
        "    pca.fit(attn_outputs)\n",
        "    pca_attn_outputs = pca.transform(attn_outputs)\n",
        "\n",
        "    title = node_location.name() + ', A'+str(answer_digit) + ', EVR[0]=' + str(pca_evr_0_percent(pca)) + '%'\n",
        "\n",
        "    return pca, pca_attn_outputs, title\n",
        "  except Exception as e:\n",
        "    print( \"calc_pca_for_an Failed:\" + node_location.name() + \" \" + qt.token_to_char(cfg, operation) + \" \" + qt.answer_name(answer_digit), e)\n",
        "    return None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk2K3y7pMlQr"
      },
      "outputs": [],
      "source": [
        "# Plot the PCA of PnLnHn's attention pattern, using T8, T9, T10 questions that differ in the An digit\n",
        "def plot_pca_for_an(ax, pca_attn_outputs, title):\n",
        "  ax.scatter(pca_attn_outputs[:qt.TRICASE_QUESTIONS, 0], pca_attn_outputs[:qt.TRICASE_QUESTIONS, 1], color='red', label='T8 (0-8)') # t8 questions\n",
        "  ax.scatter(pca_attn_outputs[qt.TRICASE_QUESTIONS:2*qt.TRICASE_QUESTIONS, 0], pca_attn_outputs[qt.TRICASE_QUESTIONS:2*qt.TRICASE_QUESTIONS, 1], color='green', label='T9') # t9 questions\n",
        "  ax.scatter(pca_attn_outputs[2*qt.TRICASE_QUESTIONS:, 0], pca_attn_outputs[2*qt.TRICASE_QUESTIONS:, 1], color='blue', label='T10 (10-18)') # t10 questions\n",
        "  if title != \"\" :\n",
        "    ax.set_title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEF7MQqCMngv"
      },
      "outputs": [],
      "source": [
        "def pca_op_tag(the_digit, operation, strong):\n",
        "  minor_tag_prefix = qt.MathsBehavior.ADD_PCA_TAG if operation == qt.MathsToken.PLUS else qt.MathsBehavior.SUB_PCA_TAG\n",
        "  return qt.answer_name(the_digit)  + \".\" + (minor_tag_prefix.value) + ( \"\" if strong else \".Weak\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PFz94tLFszr"
      },
      "outputs": [],
      "source": [
        "def manual_node_pca(ax, position, layer, num, operation, answer_digit):\n",
        "\n",
        "  node_location = qt.NodeLocation(position, layer, True, num)\n",
        "  pca, pca_attn_outputs, title = calc_pca_for_an(node_location, operation, answer_digit)\n",
        "  plot_pca_for_an(ax, pca_attn_outputs, title)\n",
        "\n",
        "  major_tag = qt.QType.MATH_ADD if operation == qt.MathsToken.PLUS else qt.QType.MATH_SUB\n",
        "  cfg.add_useful_node_tag( node_location, major_tag.value, pca_op_tag(answer_digit, operation, True) )\n",
        "\n",
        "\n",
        "def auto_node_pca(ax, index, node_location, operation, answer_digit, perc_threshold):\n",
        "\n",
        "  pca, pca_attn_outputs, title = calc_pca_for_an(node_location, operation, answer_digit)\n",
        "  if pca is not None:\n",
        "    perc = pca_evr_0_percent(pca)\n",
        "    if perc > perc_threshold:\n",
        "      plot_pca_for_an(ax, pca_attn_outputs, title)\n",
        "\n",
        "      major_tag = qt.QType.MATH_ADD if operation == qt.MathsToken.PLUS else qt.QType.MATH_SUB\n",
        "      cfg.add_useful_node_tag( node_location, major_tag.value, pca_op_tag(answer_digit, operation, False) )\n",
        "      return True\n",
        "\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkoqshK0Fvga"
      },
      "outputs": [],
      "source": [
        "def manual_nodes_pca(op, nodes):\n",
        "  print(\"Manual PCA tags for\", cfg.model_name, \"with operation\", qt.token_to_char(cfg, op))\n",
        "\n",
        "  cols = 4\n",
        "  rows = 1 + (len(nodes)+1) // cols\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.set_figheight(rows*2 + 1)\n",
        "  fig.set_figwidth(10)\n",
        "\n",
        "  index = 0\n",
        "  for node in nodes:\n",
        "    manual_node_pca(axs[index // cols, index % cols], node[0], node[1], node[2], op, node[3])\n",
        "    index += 1\n",
        "\n",
        "  # Remove any graphs we dont need (except last one)\n",
        "  while index < rows * cols - 1:\n",
        "    ax = axs[index // cols, index % cols]\n",
        "    ax.remove()\n",
        "    index += 1\n",
        "\n",
        "  # Replace last graph with the legend\n",
        "  lines_labels = [axs[0,0].get_legend_handles_labels()]\n",
        "  lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
        "  axs[rows-1, cols-1].legend(lines, labels)\n",
        "  axs[rows-1, cols-1].axis('off') # Now, to hide the last subplot\n",
        "\n",
        "  plt.tight_layout()\n",
        "  qt.save_plt_to_file(cfg=cfg, full_title='Pca Tr')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbiau9foMp3h"
      },
      "source": [
        "#Part 19B: Results: Manual interpretation of PCA results\n",
        "\n",
        "If an attention head and an answer digit An gives an interpretable response (2 or 3 distinct output clusters) on 3 groups of questions aligned to T8, T9 and T10 definitions, then plot the response and add a PCA tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ5fS3XNMs8e"
      },
      "outputs": [],
      "source": [
        "# Plot all attention heads with the clearest An selected\n",
        "if use_pca:\n",
        "\n",
        "  if cfg.model_name == \"add_d5_l2_h3_train15K\" :\n",
        "    manual_nodes_pca(qt.MathsToken.PLUS,\n",
        "      [[ 8, 0, 1, 2],\n",
        "      [  9, 0, 1, 1],\n",
        "      [ 10, 0, 1, 0],\n",
        "      [ 11, 0, 1, 3],\n",
        "      [ 11, 0, 2, 4],\n",
        "      [ 12, 0, 1, 3],\n",
        "      [ 13, 0, 1, 2],\n",
        "      [ 14, 0, 1, 1],\n",
        "      [ 15, 0, 1, 0]])\n",
        "\n",
        "  if cfg.model_name == \"add_d6_l2_h3_train15K\" :\n",
        "    manual_nodes_pca(qt.MathsToken.PLUS,\n",
        "      [[ 11, 0, 0, 2],\n",
        "      [ 12, 0, 0, 3],\n",
        "      [ 13, 0, 0, 1],\n",
        "      [ 14, 0, 0, 4],\n",
        "      [ 14, 1, 1, 4],\n",
        "      [ 15, 0, 0, 4],\n",
        "      [ 15, 1, 1, 4],\n",
        "      [ 15, 1, 2, 4],\n",
        "      [ 17, 0, 0, 2]])\n",
        "\n",
        "else:\n",
        "  print( \"PCA library failed to import. So PCA not done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIu3Pr9CMx3l"
      },
      "source": [
        "#Part 19C: Results: Automatic interpetation of PCA results\n",
        "\n",
        "Part 19B is manual and selective. This part is automatic. It tests nodes not included in Part 19B, where this first (single) principal component explains 66% or more of the node. It adds a PCA \"weak\" tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stZrlHoPJFZL"
      },
      "outputs": [],
      "source": [
        "def auto_find_pca_node(node, op, perc_threshold):\n",
        "  fig, axs = plt.subplots(2, 4) # Allow up to 8 graphs\n",
        "  fig.set_figheight(4)\n",
        "  fig.set_figwidth(10)\n",
        "\n",
        "  index = 0\n",
        "  for answer_digit in range(cfg.n_digits+1):\n",
        "    ax = axs[index // 4, index % 4]\n",
        "    if auto_node_pca(ax, index, node, op, answer_digit, perc_threshold):\n",
        "      index += 1\n",
        "\n",
        "  # Remove any graphs we dont need after all\n",
        "  while index < 2 * 4:\n",
        "    ax = axs[index // 4, index % 4]\n",
        "    ax.remove()\n",
        "    index += 1\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdfpkXmAMzg4"
      },
      "outputs": [],
      "source": [
        "def auto_find_pca(operation):\n",
        "  print(\"Automatic (weak) PCA tags for\", cfg.model_name, \"with operation\", qt.token_to_char(cfg, operation))\n",
        "  perc_threshold = 75\n",
        "\n",
        "  for node in cfg.useful_nodes.nodes:\n",
        "\n",
        "    # Exclude nodes with a (manual) PCA tag - for any answer digit(s)). Exclude MLP neurons.\n",
        "    major_tag = qt.QType.MATH_ADD if operation == qt.MathsToken.PLUS else qt.QType.MATH_SUB\n",
        "    minor_tag_prefix = qt.MathsBehavior.ADD_PCA_TAG if operation == qt.MathsToken.PLUS else qt.MathsBehavior.SUB_PCA_TAG\n",
        "    if node.is_head and not node.contains_tag(major_tag.value, minor_tag_prefix.value):\n",
        "      print( \"Doing PCA on node\", node.name())\n",
        "\n",
        "      auto_find_pca_node(node, operation, perc_threshold)\n",
        "\n",
        "if False: # Suppressed for speed\n",
        "  if use_pca:\n",
        "    if cfg.perc_add() > 0:\n",
        "      auto_find_pca(qt.MathsToken.PLUS)\n",
        "    if cfg.perc_sub > 0:\n",
        "      auto_find_pca(qt.MathsToken.MINUS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcCpfmKwlAH"
      },
      "source": [
        "# Part 20A: Results: Show useful nodes and behaviour tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i6q2-lcgp5w"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.sort_nodes()\n",
        "cfg.useful_nodes.print_node_tags()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeTKpLA4JVv8"
      },
      "source": [
        "# Part 20B: Results: Save useful nodes and behaviour tags to json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7KDdivbJY3G"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the useful nodes list to a temporary CoLab file in JSON format\n",
        "print( \"Saving useful node list with behavior tags:\", main_fname_behavior_json)\n",
        "cfg.useful_nodes.save_nodes(main_fname_behavior_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bbeIfUxvLzl"
      },
      "source": [
        "# Part 21 : Set up: Interchange Interventions\n",
        "\n",
        "Set up a framework to run the model with two questions:\n",
        "- The first \"store\" question is run without hooks\n",
        "- The second \"clean\" question is run with hooks interjecting some data from the \"store\" run. This run gives, not a \"clean\" answer, but an \"intervened\" answer, which mixes the \"store\" answer and the \"clean\" answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk0gVCF9Gr5D"
      },
      "outputs": [],
      "source": [
        "def run_intervention_core(node_locations, store_question, clean_question, operation, expected_answer_impact, expected_answer_int, strong):\n",
        "  assert(len(node_locations) > 0)\n",
        "  assert(store_question[0] < + 10 ** cfg.n_digits)\n",
        "  assert(store_question[1] > - 10 ** cfg.n_digits)\n",
        "  assert(store_question[0] < + 10 ** cfg.n_digits)\n",
        "  assert(store_question[1] > - 10 ** cfg.n_digits)\n",
        "  assert(clean_question[0] < + 10 ** cfg.n_digits)\n",
        "  assert(clean_question[1] > - 10 ** cfg.n_digits)\n",
        "  assert(clean_question[0] < + 10 ** cfg.n_digits)\n",
        "  assert(clean_question[1] > - 10 ** cfg.n_digits)\n",
        "\n",
        "  # Calculate the test (clean) question answer e.g. \"+006671\"\n",
        "  clean_answer_int = clean_question[0]+clean_question[1] if operation == qt.MathsToken.PLUS else clean_question[0]-clean_question[1]\n",
        "  clean_answer_str = qt.int_to_answer_str(cfg, clean_answer_int)\n",
        "  expected_answer_str = qt.int_to_answer_str(cfg, expected_answer_int)\n",
        "\n",
        "  # Matrices of tokens\n",
        "  store_question_and_answer = qt.make_maths_questions_and_answers(cfg, acfg.operation, qt.QType.UNKNOWN, qt.MathsBehavior.UNKNOWN, [store_question])\n",
        "  clean_question_and_answer = qt.make_maths_questions_and_answers(cfg, acfg.operation, qt.QType.UNKNOWN, qt.MathsBehavior.UNKNOWN, [clean_question])\n",
        "\n",
        "  acfg.reset_intervention(expected_answer_str, expected_answer_impact, operation)\n",
        "  acfg.ablate_node_locations = node_locations\n",
        "\n",
        "  run_description = qt.a_run_attention_intervention(cfg, store_question_and_answer, clean_question_and_answer, clean_answer_str)\n",
        "\n",
        "  return \"Intervening on \" + acfg.node_names() + \", \" + (\"Strong\" if strong else \"Weak\") + \", Node[0]=\" + acfg.ablate_node_locations[0].name() + \", \" + run_description\n",
        "\n",
        "\n",
        "# Run an intervention where we have a precise expectation of the intervention impact\n",
        "def run_strong_intervention(node_locations, store_question, clean_question, operation, expected_answer_impact, expected_answer_int):\n",
        "\n",
        "  # These are the actual model prediction outputs (while applying our node-level intervention).\n",
        "  description = run_intervention_core(node_locations, store_question, clean_question, operation, expected_answer_impact, expected_answer_int, True)\n",
        "\n",
        "  answer_success = (acfg.intervened_answer == acfg.expected_answer)\n",
        "  impact_success = (acfg.intervened_impact == acfg.expected_impact)\n",
        "  success = answer_success and impact_success\n",
        "\n",
        "  if acfg.show_test_failures and not success:\n",
        "    print(\"Failed: \" + description)\n",
        "\n",
        "  return success, answer_success, impact_success\n",
        "\n",
        "\n",
        "# Run an intervention where we expect the intervention to have a non-zero impact and we cant precisely predict the answer\n",
        "def run_weak_intervention(node_locations, store_question, clean_question, operation):\n",
        "\n",
        "  # Calculate the test (clean) question answer e.g. \"+006671\"\n",
        "  expected_answer_int = clean_question[0]+clean_question[1] if operation == qt.MathsToken.PLUS else clean_question[0]-clean_question[1]\n",
        "\n",
        "  description = run_intervention_core(node_locations, store_question, clean_question, operation, qt.NO_IMPACT_TAG, expected_answer_int, False)\n",
        "\n",
        "  success = not ((acfg.intervened_answer == acfg.expected_answer) or (acfg.intervened_impact == qt.NO_IMPACT_TAG))\n",
        "\n",
        "  if acfg.show_test_failures and not success:\n",
        "    print(\"Failed: Intervention had no impact on the answer\", description)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ8Z2kJ2JpZH"
      },
      "outputs": [],
      "source": [
        "def repeat_digit(digit):\n",
        "    return int(str(digit) * cfg.n_digits)\n",
        "\n",
        "\n",
        "# unit test\n",
        "if cfg.n_digits == 6:\n",
        "  assert repeat_digit(4) == 444444"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbAsO6sFJrR6"
      },
      "outputs": [],
      "source": [
        "def succeed_test(node_locations, alter_digit, strong):\n",
        "  print( \"Test confirmed\", node_locations[0].name(), node_locations[1].name() if len(node_locations)>1 else \"\", \"\" if strong else \"Weak\")\n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqTfjKMBPKdE"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.reset_node_tags(qt.QType.ALGO.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iosx5zE_macF"
      },
      "source": [
        "## Part 21C: Automated An.SA search\n",
        "\n",
        "Search for addition \"Simple Add\" (SA) tasks e.g. 555555+111111=+0666666 where D3 + D'3 < 10\n",
        "\n",
        "The SA tasks is sometimes split/shared over 2 attention heads in the same position and layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8HHyLpHKDxS"
      },
      "outputs": [],
      "source": [
        "def add_sa_tag(the_digit):\n",
        "  return qt.answer_name(the_digit) + \".\" + qt.MathsTask.SA_TAG.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyerrtNQKPcg"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) an Addition BaseAdd node\n",
        "def add_sa_prereqs(cfg, position, impact_digit):\n",
        "  return qt.FilterAnd(\n",
        "    qt.FilterHead(),\n",
        "    qt.FilterPosition(qt.position_name(position)),\n",
        "    qt.FilterAttention(cfg.dn_to_position_name(impact_digit)), # Attends to Dn\n",
        "    qt.FilterAttention(cfg.ddn_to_position_name(impact_digit)), # Attends to D'n\n",
        "    qt.FilterImpact(qt.answer_name(impact_digit)), # Impacts An\n",
        "    qt.FilterAlgo(add_sa_tag(impact_digit), qt.QCondition.NOT)) # Has not already been flagged as a BA task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-Gs5yglncax"
      },
      "outputs": [],
      "source": [
        "def add_sa_test(cfg, acfg, node_locations, alter_digit, strong):\n",
        "  intervention_impact = qt.answer_name(alter_digit)\n",
        "\n",
        "  store_question = [repeat_digit(2), repeat_digit(3)] # 222222 + 333333 = 555555\n",
        "  clean_question = [repeat_digit(5), repeat_digit(4)] # 555555 + 444444 = 999999\n",
        "  intervened_answer = repeat_digit(9) + (5 - 9) * (10 ** alter_digit)\n",
        "  success1, answer_success1, impact_success1 = run_strong_intervention(node_locations, store_question, clean_question, qt.MathsToken.PLUS, intervention_impact, intervened_answer)\n",
        "\n",
        "  store_question = [repeat_digit(2), repeat_digit(1)] # 222222 + 111111 = 333333\n",
        "  clean_question = [repeat_digit(5), repeat_digit(4)] # 555555 + 444444 = 999999\n",
        "  intervened_answer = int(repeat_digit(9)) + (3 - 9) * (10 ** alter_digit)\n",
        "  success2, answer_success2, impact_success2 = run_strong_intervention(node_locations, store_question, clean_question, qt.MathsToken.PLUS, intervention_impact, intervened_answer)\n",
        "\n",
        "  success = (success1 and success2) if strong else (impact_success1 and impact_success2)\n",
        "\n",
        "  if success:\n",
        "    print( \"Test confirmed:\", acfg.node_names(), \"perform A\"+str(alter_digit)+\".SA = (D\"+str(alter_digit)+\" + D'\"+str(alter_digit)+\") % 10 impacting \"+intervention_impact+\" accuracy.\", \"\" if strong else \"Weak\", acfg.intervened_answer)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIktdaRL-BfP"
      },
      "outputs": [],
      "source": [
        "#cfg.useful_nodes.reset_node_tags(QType.ALGO.value)\n",
        "#acfg.show_test_failures = True\n",
        "qt.search_and_tag( cfg, acfg, add_sa_prereqs, add_sa_test, add_sa_tag, True, True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5DMV3I_25ST"
      },
      "source": [
        "## Part 22C: Automated An.SC search\n",
        "\n",
        "Search for addition \"Make Carry 1\" (SC) tasks e.g. 222222+666966=+0889188 where D2 + D'2 > 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_8nNue_L5ZN"
      },
      "outputs": [],
      "source": [
        "def add_sc_tag(impact_digit):\n",
        "  return qt.answer_name(impact_digit-1)  + \".\" + qt.MathsTask.SC_TAG.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpoiCG0bL8ZK"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) an Addition MakeCarry node\n",
        "def add_sc_prereqs(cfg, position, impact_digit):\n",
        "  return qt.FilterAnd(\n",
        "    qt.FilterHead(),\n",
        "    qt.FilterPosition(qt.position_name(position)),\n",
        "    qt.FilterAttention(cfg.dn_to_position_name(impact_digit-1)), # MC is calculated on the next lower-value digit.\n",
        "    qt.FilterAttention(cfg.ddn_to_position_name(impact_digit-1)), # MC is calculated on the next lower-value digit.\n",
        "    qt.FilterImpact(qt.answer_name(impact_digit)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJBYT0hF3R_u"
      },
      "outputs": [],
      "source": [
        "def add_sc_test(cfg, acfg, node_locations, impact_digit, strong):\n",
        "  alter_digit = impact_digit - 1\n",
        "\n",
        "  if alter_digit < 0 or alter_digit >= cfg.n_digits:\n",
        "    acfg.reset_intervention()\n",
        "    return False\n",
        "\n",
        "  intervention_impact = qt.answer_name(impact_digit)\n",
        "\n",
        "  # 222222 + 666966 = 889188. Has Dn.MC\n",
        "  store_question = [repeat_digit(2), repeat_digit(6)]\n",
        "  store_question[1] += (9 - 6) * (10 ** alter_digit)\n",
        "\n",
        "  # 333333 + 555555 = 888888. No Dn.MC\n",
        "  clean_question = [repeat_digit(3), repeat_digit(5)]\n",
        "\n",
        "  # When we intervene we expect answer 889888\n",
        "  intervened_answer = clean_question[0] + clean_question[1] + 10 ** (alter_digit+1)\n",
        "\n",
        "  success, _, _ = run_strong_intervention(node_locations, store_question, clean_question, qt.MathsToken.PLUS, intervention_impact, intervened_answer)\n",
        "\n",
        "  if success:\n",
        "    print( \"Test confirmed\", acfg.node_names(), \"perform A\"+str(alter_digit)+\".SC impacting \"+intervention_impact+\" accuracy.\", \"\" if strong else \"Weak\")\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvS1eOReZUq1"
      },
      "outputs": [],
      "source": [
        "qt.search_and_tag( cfg, acfg, add_sc_prereqs, add_sc_test, add_sc_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThzFD1FxBXg8"
      },
      "source": [
        "## Part 22E: Automated Dn.ST search\n",
        "\n",
        "Search for D0.ST to D5.ST with impact \"A65432\" to \"A65\" in early tokens.\n",
        "\n",
        "A0 and A1 are too simple to need Dn.ST values so they are excluded from the answer impact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj5e_JOMMQ2e"
      },
      "outputs": [],
      "source": [
        "def add_st_tag(focus_digit):\n",
        "  return \"D\" + str(focus_digit) + \".\" + qt.MathsTask.ST_TAG.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZvfYWBxMRaz"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) an Addition Dn.ST node\n",
        "def add_st_prereqs(cfg, position, focus_digit):\n",
        "  return qt.FilterAnd(\n",
        "    qt.FilterHead(),\n",
        "    qt.FilterPosition(qt.position_name(position)),\n",
        "    qt.FilterAttention(cfg.dn_to_position_name(focus_digit)), # Attends to Dn\n",
        "    qt.FilterAttention(cfg.ddn_to_position_name(focus_digit)), # Attends to D'n\n",
        "    qt.FilterContains(qt.QType.MATH_ADD, qt.MathsBehavior.ADD_PCA_TAG.value)) # Node PCA is interpretable (bigram or trigram output) with respect to T8,T9,T10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-bcEooQBp2v"
      },
      "outputs": [],
      "source": [
        "def add_st_test(cfg, acfg, node_locations, focus_digit, strong):\n",
        "  # 222222 + 777977 = 1000188. Has Dn.MC\n",
        "  store_question = [repeat_digit(2), repeat_digit(7)]\n",
        "  store_question[1] += (9 - 7) * (10 ** focus_digit)\n",
        "\n",
        "  # 333333 + 666666 = 999999. No Dn.MC\n",
        "  clean_question = [repeat_digit(3), repeat_digit(6)]\n",
        "\n",
        "  success = run_weak_intervention(node_locations, store_question, clean_question, qt.MathsToken.PLUS)\n",
        "\n",
        "  if success:\n",
        "    description = acfg.node_names() + \" perform D\"+str(focus_digit)+\".C = TriCase(D\"+str(focus_digit)+\" + D'\"+str(focus_digit)+\")\"\n",
        "    print(\"Test confirmed\", description, \"Impact:\", acfg.intervened_impact, \"\" if strong else \"Weak\")\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFJV4pfWSwHQ"
      },
      "outputs": [],
      "source": [
        "qt.search_and_tag( cfg, acfg, add_st_prereqs, add_st_test, add_st_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQLfkdlbVAl_"
      },
      "source": [
        "# Part 21D: Show algorithm quanta map\n",
        "\n",
        "Plot the \"algorithm\" tags generated in previous steps as a quanta map. This is an automatically generated partail explanation of the model algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqjrGhJ6TS6U"
      },
      "outputs": [],
      "source": [
        "qt.print_algo_purpose_results(cfg)\n",
        "print()\n",
        "\n",
        "show_quanta_map( \"Maths Purpose Per Node\", qt.QType.ALGO, \"\", qt.get_quanta_binary, cell_num_shades = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhheXmLTUfc"
      },
      "source": [
        "# Part21E: Save useful nodes and tags to JSON file\n",
        "\n",
        "Show a list of the nodes that have proved useful in calculations.\n",
        "For each useful node, show its useful facts, stored as tags.\n",
        "Save the data to a Colab temporary JSON file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRW6tiM8hDOB"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.print_node_tags(qt.QType.ALGO.value, \"\", False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ktlEftAOyEd"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the useful nodes list with algorithm tags to a temporary CoLab file in JSON format\n",
        "print( \"Saving useful node list with algorithm tags:\", main_fname_algorithm_json)\n",
        "cfg.useful_nodes.save_nodes(main_fname_algorithm_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMnvjPxN6wZ7"
      },
      "source": [
        "# Part 21F: TBA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDt2LmNwiMGA"
      },
      "outputs": [],
      "source": [
        "print( \"Claim that P10.L0.H1 performs D1.C2 = TriAdd(V1.C, TriCase(D0, D0)) impacting A5, A4, A3 & A2 accuracy\")\n",
        "print()\n",
        "nodes = [qt.NodeLocation(10, 0, True, 1)]\n",
        "\n",
        "store_question = [ 11111, 33333] # Sum is 044444. V0 has no MC.\n",
        "clean_question = [ 44444, 55555] # Sum is 099999. V0 has no MC\n",
        "run_strong_intervention( nodes, store_question, clean_question, qt.MathsToken.PLUS, qt.NO_IMPACT_TAG, 99999 )\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "clean_question = [ 44444, 55555] # Sum is 099999. V0 has no MC\n",
        "run_strong_intervention( nodes, store_question, clean_question, qt.MathsToken.PLUS, \"A5432\", 100099 )\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "clean_question = [  4444,  5555] # Sum is 009999. V0 has no MC\n",
        "run_strong_intervention( nodes, store_question, clean_question,qt.MathsToken.PLUS, \"A432\", 10099 )\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "clean_question = [   444,   555] # Sum is 000999. V0 has no MC\n",
        "run_strong_intervention( nodes, store_question, clean_question, qt.MathsToken.PLUS, \"A32\", 1099 )\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "clean_question = [    44,    55] # Sum is 000099. V0 has no MC\n",
        "run_strong_intervention( nodes, store_question, clean_question, qt.MathsToken.PLUS, \"A2\", 199 )\n",
        "\n",
        "# Deprecated: Confirmed that P10.L0.H1 is: Based on D0 and D0'. Triggers on a V0 carry value. Provides \"carry 1\" used in A5, A4, A3 & A2 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxGCodzep7qV"
      },
      "outputs": [],
      "source": [
        "print( \"Claim that P11.L0.H1 performs D3.C4 = TriAdd(TriCase(D3, D3),TriAdd(V2.C,V1.C2)) impacting A5 accuracy\")\n",
        "print()\n",
        "nodes = [qt.NodeLocation(11, 0, True, 1)]\n",
        "\n",
        "store_question = [44444, 44444] # Sum is 088888. V3 sums to 8 (has no MC).\n",
        "clean_question = [11111, 11111] # Sum is 022222. V3 has no MC.\n",
        "run_strong_intervention( nodes, store_question, clean_question, qt.MathsToken.PLUS, qt.NO_IMPACT_TAG, 22222 )\n",
        "\n",
        "store_question = [16111, 13111] # Sum is 032111. V3 sums to 9 (has no MC).\n",
        "clean_question = [44444, 55555] # Sum is 099999. V3 has no MC\n",
        "run_strong_intervention( nodes, store_question, clean_question, qt.MathsToken.PLUS, qt.NO_IMPACT_TAG, 99999 )\n",
        "\n",
        "store_question = [16111, 16111] # Sum is 032111. V3 has MC\n",
        "clean_question = [44444, 55555] # Sum is 099999. V3 has no MC\n",
        "run_strong_intervention( nodes, store_question, clean_question,qt.MathsToken.PLUS, \"A5\", 199999 )\n",
        "\n",
        "# Deprecated: Confirmed that P11.L0.H1 is: Based on D3 and D3'. Triggers on a V3 carry value. Provides \"carry 1\" used in A5 calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo55vCvCoMq7"
      },
      "outputs": [],
      "source": [
        "print( \"Claim that P11.L0.H2 performs D4.C = TriCase(D4, D4) impacting A5 accuracy\")\n",
        "print()\n",
        "nodes = [qt.NodeLocation(11, 0, True, 2)]\n",
        "\n",
        "store_question = [44444, 55555] # Sum is 099999. V4 has no MC.\n",
        "clean_question = [11111, 11111] # Sum is 022222. V4 has no MC.\n",
        "run_strong_intervention( nodes, store_question, clean_question, qt.MathsToken.PLUS, qt.NO_IMPACT_TAG, 22222)\n",
        "\n",
        "store_question = [71111, 71111] # Sum is 100422. V4 has MC\n",
        "clean_question = [44444, 55555] # Sum is 099999. V4 has no MC\n",
        "run_strong_intervention( nodes, store_question, clean_question, qt.MathsToken.PLUS, \"A5\", 199999 )\n",
        "\n",
        "# Deprecated: Confirmed that P9.L0.H2 is: Based on D4 and D4'. Triggers on a V4 carry value. Provides \"carry 1\" used in A5 calculation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTs6Cu55jB7y"
      },
      "source": [
        "#Part 22: MLP Visualisation (incomplete, on-hold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YviVHnBRjDcs"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def get_mlp_data(data_set_name):\n",
        "  cfg.main_model.reset_hooks()\n",
        "  cfg.main_model.set_use_attn_result(True)\n",
        "  sample_logits, sample_cache = cfg.main_model.run_with_cache(varied_questions.cuda())\n",
        "  data_set = sample_cache[data_set_name]\n",
        "  # print( data_set_name + \" shape\", data_set.shape) # 239, 22, 2040 = num_varied_questions, cfg.n_ctx, cfg.d_mlp\n",
        "\n",
        "  raw_data = data_set[:,-3]\n",
        "  # print( \"raw_data shape\", raw_data.shape) # 239, 2040 = num_varied_questions, cfg.d_mlp\n",
        "\n",
        "  answer = einops.rearrange(raw_data, \"(x y) d_mlp -> x y d_mlp\", x=num_varied_questions).cpu().numpy()\n",
        "  # print( \"answer shape\", answer.shape) # 239, 1, 2040 = num_varied_questions, ??, cfg.d_mlp\n",
        "\n",
        "  return answer\n",
        "\n",
        "\n",
        "l0_mlp_hook_pre_sq = get_mlp_data('blocks.0.mlp.hook_pre')\n",
        "l0_mlp_hook_post_sq = get_mlp_data('blocks.0.mlp.hook_post')\n",
        "l1_mlp_hook_pre_sq = get_mlp_data('blocks.1.mlp.hook_pre') if cfg.n_layers > 1 else l0_mlp_hook_pre_sq\n",
        "l1_mlp_hook_post_sq = get_mlp_data('blocks.1.mlp.hook_post') if cfg.n_layers > 1 else l0_mlp_hook_post_sq\n",
        "\n",
        "\n",
        "def plot_mlp_neuron_activation(pos: int):\n",
        "    clear_output()\n",
        "\n",
        "    l0_mlp_pre_data = l0_mlp_hook_pre_sq[:,:,pos]\n",
        "    l0_mlp_post_data = l0_mlp_hook_post_sq[:,:,pos]\n",
        "    l1_mlp_pre_data = l1_mlp_hook_pre_sq[:,:,pos]\n",
        "    l1_mlp_post_data = l1_mlp_hook_post_sq[:,:,pos]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(8,4))\n",
        "\n",
        "    plot = axs[0].imshow(l1_mlp_pre_data, cmap='magma', vmin=0, vmax=1)\n",
        "    cbar = plt.colorbar(plot, fraction=0.1)\n",
        "    cbar.set_label(r'l0_mlp_pre_data {}'.format(pos))\n",
        "    #axs[0].set_ylim(-0.5, 99.5)\n",
        "    #axs[0].set_yticks(range(100), labels=range(100), size=5.5);\n",
        "    #axs[0].set_xticks(range(100), labels=range(100), size=5.5, rotation='vertical');\n",
        "\n",
        "    plot = axs[1].imshow(l1_mlp_post_data, cmap='magma', vmin=0, vmax=1)\n",
        "    cbar = plt.colorbar(plot, fraction=0.1)\n",
        "    cbar.set_label(r'l0_mlp_post_data {}'.format(pos))\n",
        "    #axs[0].set_ylim(-0.5, 99.5)\n",
        "    #axs[0].set_yticks(range(100), labels=range(100), size=5.5);\n",
        "    #axs[0].set_xticks(range(100), labels=range(100), size=5.5, rotation='vertical');\n",
        "\n",
        "\n",
        "interact(plot_mlp_neuron_activation, pos=widgets.IntText(value=0, description='Index:'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PjaQvhhayUL"
      },
      "source": [
        "# Part 25 : Results: Can the model do 1 million questions without error?\n",
        "\n",
        "If the model passes this test, this is evidence (not proof) that the model is fully accurate. There may be very rare edge cases (say 1 in ten million) that did not appear in the test questions. Even if you believe you know all the edge cases, and have enriched the training data to contain them, you may not have thought of all edge cases, so this is not proof.\n",
        "\n",
        "If the model fails this test:\n",
        "- Add a few of the failures into the \"test questions\" in part 6C\n",
        "- Understand the \"use case(s)\" driving these failures\n",
        "- Alter the Training CoLab data_generator_core to enrich the training data with examples if these use case(s) and retrain the model.  \n",
        "\n",
        "Takes ~25 mins to run (successfully) for ins_mix_d6_l3_h4_train40K_seed372001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMYZTv5HUp5F"
      },
      "outputs": [],
      "source": [
        "def one_million_questions_core():\n",
        "  global ds\n",
        "\n",
        "  acfg.verbose = False\n",
        "\n",
        "  cfg.analysis_seed = 345621 # Randomly chosen\n",
        "  ds = qt.maths_data_generator() # Re-initialise the data generator\n",
        "\n",
        "  the_successes = 0\n",
        "  the_fails = 0\n",
        "\n",
        "  num_batches = 1000000//cfg.batch_size\n",
        "  for epoch in range(num_batches):\n",
        "      tokens = next(ds)\n",
        "\n",
        "      the_fails = qt.test_maths_questions_by_impact(cfg, acfg, tokens, 0, False)\n",
        "\n",
        "      if the_fails> 0:\n",
        "        break\n",
        "\n",
        "      the_successes = the_successes + cfg.batch_size\n",
        "\n",
        "      if epoch % 100 == 0:\n",
        "          print(\"Batch\", epoch, \"of\", num_batches, \"#Successes=\", the_successes)\n",
        "\n",
        "  print(\"successes\", the_successes, \"num_fails\", the_fails)\n",
        "  if the_fails > 0:\n",
        "    \"WARNING: Model is not fully accurate. It failed the 1M Q test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znsauYqjaxok"
      },
      "outputs": [],
      "source": [
        "def one_million_questions():\n",
        "  store_perc_sub = cfg.perc_sub\n",
        "  store_perc_mult = cfg.perc_mult\n",
        "\n",
        "  print_config()\n",
        "  print()\n",
        "\n",
        "  if cfg.perc_add() > 0:\n",
        "    print(\"Addition:\")\n",
        "    cfg.perc_sub = 0\n",
        "    cfg.perc_mult = 0\n",
        "    one_million_questions_core()\n",
        "\n",
        "  if store_perc_sub > 0:\n",
        "    print(\"Subtraction:\")\n",
        "    cfg.perc_sub = 100\n",
        "    cfg.perc_mult = 0\n",
        "    one_million_questions_core()\n",
        "    print()\n",
        "\n",
        "  cfg.perc_sub = store_perc_sub\n",
        "  cfg.perc_mult = store_perc_mult\n",
        "\n",
        "\n",
        "# Takes ~25 minutes to run\n",
        "# one_million_questions()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "xozmbk84Hl9v",
        "P8RfHXneJw6n",
        "tz6rUaYvjOcE",
        "ZHiJhch4KCej",
        "-KJhCxFtNKfm",
        "I-yFKiDllqEf",
        "D6FwJW0tv4Nf",
        "2U7dq4AtDYt3",
        "ZmsGWUbILYin",
        "904WBkTOLg_5",
        "H0pyEjrqEU27",
        "jIu3Pr9CMx3l",
        "jFcCpfmKwlAH",
        "SeTKpLA4JVv8",
        "7bbeIfUxvLzl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}