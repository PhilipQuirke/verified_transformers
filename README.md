<p align="center">
    <br>
    <img src="./assets/apart_banner.png" width="900"/>
    <br>
<p>

## Introduction
This library support goals and uses [terminology](./terminology.md) introduced in the paper [Increasing Trust in Language Models through the Reuse of Verified Circuits](https://arxiv.org/abs/2402.02619). Please read the paper. In brief:
- Given an existing transformer model with low loss, this library helps a researcher to analyze and understand the algorithm implemented by a transformer model.
- The "useful" token positions, attention heads and MLP neurons that are used in predictions are identified.  
- Various tools and techniques evaluate aspects of the model's "behavior" (e.g. attention patterns).
- The researcher can extend the tools with model-specific searches and tests - searching for hypothesised model components that perform model-specific algorithm "sub-tasks" (e.g. Base Add in the Addition model)
- Useful facts found in this way are stored as JSON (refer [Useful_Tags](./useful_tags.md) for details) and can be visualized (refer [Assets](./Assets/"Assets") for samples).
- A researcher can describe an algorithm hypothesis as a series of claims, and evaluate those claims against the facts found. The resulting insights can be used to refine and\or extend both the algorithm sub-task tests and the algorithm hypothesis description, leading to a full description of the model's algorithm.

## Installation

From source

```bash
git clone https://github.com/PhilipQuirke/verified_transformers.git
cd verified_transformers
pip install .
```

## Test bed
Much of this library is generic (can be applied to any transformer model). As a "real-world" testbed to help refine this library we use models trained to perform integer addition and subtraction (e.g. 133357+182243=+0315600 and 123450-345670=-0123230). Arithmetic-specific algorithm sub-task searches are defined (e.g. Base Add, Use Sum 9, Make Carry, Base Subtract, Borrow One). Addition and Subtraction hypothesises are described and evaluated in the Colab notebook VerifiedArithmeticAnalyse.ipynb. Arithmetic-specific python code is in files like [maths_config.py](./QuantaTools/maths_config.py).   

## Folders, Files and Classes 
This library contains files:

- **Notebooks:** Jupyter notebooks which are run in Google Colab or Jupyter: 
  - **Train:** Colab VerifiedArithmeticTrain.ipynb is used to train transformer arithmetic models. 
    - Outputs pth and json files that are (manually) stored on HuggingFace
  - **Analysis:** Colab VerifiedArithmeticAnalyse.ipynb is used to analyze the behavior and algorithm sub-tasks of transformer arithmetic models
    - Inputs pth files (generated above) from HuggingFace
    - Outputs *_behavior and *_algorithm json files that are (manually) stored on HuggingFace
  - **Algorithm:** Colab VerifiedArithmeticAlgorithm.ipynb describes/tests an overall algorithm for a model (based on behavior and algorithm sub-tasks data)
    - Inputs *_behavior and *_algorithm json files (generated above) from HuggingFace 

- **QuantaTools:** Python library code imported into the notebooks:
  - model_*.py: Contains the configuration of the transformer model being trained/analysed. Includes class ModelConfig 
  - useful_*.py: Contains data on the useful token positions and useful nodes (attention heads and MLP neurons) that the model uses in predictions. Includes class UsefulConfig derived from ModelConfig. Refer [Useful_Tags](./useful_tags.md) for more detail. 
  - algo_*.py: Contains tools to support declaring and validating a model algorithm. Includes class AlgoConfig derived from UsefulConfig.
  - quanta_*.py: Contains categorisations of model behavior (aka quanta), with ways to detect, filter and graph them. Refer [Filter](./filter.md) for more detail. 
  - ablate_*.py: Contains ways to "intervention ablate" the model and detect the impact of the ablation
  - maths_*.py: Contains specializations of the above specific to arithmetic (addition and subtraction) transformer models. Includes class MathsConfig derived from AlgoConfig.
          
- **Tests:** Unit tests 

## HuggingFace resources
The HuggingFace website holds the output files generated by the CoLab notebooks for ~14 models. The main focus is on these models:

- add_d5_l1_h3_t30K_s372001: Inaccurate **5-digit, 1-layer, 3-attention-head**, addition model. This reproduces Paper 1.
- add_d5_l2_h3_t15K_s372001: **Accurate** 5-digit, **2-layers**, 3-head addition model trained for 15K epochs. 
- add_d6_l2_h3_t15K_s372001: **Accurate** **6-digit**, 2-layers, 3-head addition model trained for 15K epochs.  
- ins1_mix_d6_l3_h4_t40K_s372001: **Accurate** 6-digit, 3-layers, 4-head mixed (addition and subtraction) model **initialised with addition model** add_d6_l2_h3_t15K_s372001. 

For each model these output files available are:
- model's weight (xxxxxxx.pth),
- model's training details (xxxxxxx_train.json),
- generic analysis facts (xxxxxxx_behavior.json), and
- maths-specific facts (xxxxxxx_maths.json)

Refer [Hugging_Models](./hugging_models.md) for more detail.

## Papers
The papers associated with this content are:
- Understanding Addition in Transformers: https://arxiv.org/abs/2310.13121 . Aka Paper1. Model add_d5_l1_h3_t30K is very similar to the one in this paper. 
- Increasing Trust in Language Models through the Reuse of Verified Circuits. https://arxiv.org/abs/2402.02619 . Aka Paper2. Uses many of these models mostly focusing on add_d5_l2_h3_t15K, add_d6_l2_h3_t15K and ins1_mix_d6_l3_h4_t40K

## Extending the code
Most exploratory work is done in a Google Colab in the 'train and 'analyse' notebooks. 
After a new 'search' is successfully developed and tested in the notebook, the code is migrated to the QuantaTools code folder. 
